{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Progress Report 1\n",
    "----\n",
    "\n",
    "**Team Members**\n",
    "\n",
    "Yaqian Cheng, Department of Statistical Science\n",
    "\n",
    "Mengrun Li, Department of Statistical Science\n",
    "\n",
    "**Github repository**\n",
    "\n",
    "<https://github.com/cici7941/Sta_663_Statistical_Computation_Final_Project>\n",
    "\n",
    "**Choice of paper** \n",
    "\n",
    "*Scalable K-Means++*\n",
    "\n",
    "**Abstract**\n",
    "\n",
    "*K-means* is one of the most popular clustering methods. A good initialization of *k-means* is essential for obtaining the global optimal solution and efficiency. However, there are two main obstacles with traditional *k-means* method. One is theoretical inefficiency and the other one is that its final solution is locally optimal. A better algorithm, *k-means++* addresses the second problem with an improved initialization procedure of the cluster centers. But this *k-means++* initialization is not parallelizable, because the selection for the *i*th center depends on the previous *i-1* centers [1]. Therefore, *k-means||*, a parallelizable version of *k-means++*, has been raised, which can both improve the final solution and run faster. In this report, we implemented the algorithm in the paper \"Scalable K-Means++\" in Python, compared the clustering cost and runtime between *k-means*, *k-means++* and *k-means||*, performed tests for main functions, profiled the performance of the algorithm and identified bottlenecks, and performed optimization using Cython. We then apply *k-means||* to a massive dataset to evaluate its performance.\n",
    "\n",
    "**Outline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "2. Algorithm  \n",
    "    2.1 K-Means  \n",
    "    2.2 K-Means++  \n",
    "    2.3 K-Means||  \n",
    "3. Code Testing\n",
    "4. Profiling and Optimization\n",
    "5. Application and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.linalg as la\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def euc_dist(x, y):\n",
    "    return la.norm(x-y)\n",
    "\n",
    "def centroid(X):\n",
    "    return X.mean(0)\n",
    "    \n",
    "def d(x, Y):\n",
    "    minDist = float(\"inf\")\n",
    "    for yi in Y:\n",
    "        dist = euc_dist(x, yi)\n",
    "        if(dist < minDist):\n",
    "            minDist = dist\n",
    "    return minDist\n",
    "\n",
    "def cost(Y, C):\n",
    "    cost = 0\n",
    "    for yi in Y:\n",
    "        cost += d(yi, C)**2\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# K-Means++\n",
    "def kmeansPlus(data, k):\n",
    "    idx = np.random.choice(data.shape[0], 1)\n",
    "    C = data[idx, :]\n",
    "    while(C.shape[0] < k):\n",
    "        prob = [d(xi,C)**2 for xi in data]/cost(data,C)\n",
    "        new = data[np.random.choice(data.shape[0], size=1, p=prob),:]\n",
    "        if(new.tolist() not in C.tolist()):\n",
    "            C = np.r_[C, new]\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\n",
      "first centroid: [[77 34]]\n",
      "initial cost: 39747.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1,   0],\n",
       "       [  2,   0],\n",
       "       [  3,   5],\n",
       "       [  6,  88],\n",
       "       [ 24,  66],\n",
       "       [ 90,  12],\n",
       "       [ 26,  23],\n",
       "       [ 91, 100]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K-Means||\n",
    "X_ori = np.array([[1,0],[2,0],[3,5],[77,34],[6,88],[24,66],[90,12],[26,23],[91,100]])\n",
    "X = X_ori\n",
    "k = 3\n",
    "l = 2\n",
    "##step1\n",
    "##Sample a point uniformly at random from X\n",
    "idx1 = np.random.choice(X_ori.shape[0],1,replace = False)\n",
    "C = X[idx1-1]\n",
    "print(idx1)\n",
    "print(\"first centroid:\",C)\n",
    "##step2\n",
    "##initial cost\n",
    "gamma1 = cost(X,C)\n",
    "print(\"initial cost:\",gamma1)\n",
    "##remove first centroid\n",
    "X = np.delete(X, idx1-1, axis=0)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##step3\n",
    "for i in range(int(round(np.log(gamma1)))):\n",
    "    #Ct = np.array([])\n",
    "    gamma = cost(X,C)\n",
    "    for idx in range(X.shape[0]):\n",
    "        p = l*(d(X[idx,:],C))**2/gamma\n",
    "        point = np.random.uniform(size = 1)\n",
    "        if point < p:\n",
    "           C = np.concatenate((C,[X[idx,:].tolist()]),axis = 0)\n",
    "           X = np.delete(X,idx,axis = 0)\n",
    "    #C = np.concatenate((C,Ct),axis = 0)\n",
    "C"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
