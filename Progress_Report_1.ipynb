{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Progress Report 1\n",
    "----\n",
    "\n",
    "**Team Members**\n",
    "\n",
    "Yaqian Cheng, Department of Statistical Science\n",
    "\n",
    "Mengrun Li, Department of Statistical Science\n",
    "\n",
    "**Github repository**\n",
    "\n",
    "<https://github.com/cici7941/Sta_663_Statistical_Computation_Final_Project>\n",
    "\n",
    "**Choice of paper** \n",
    "\n",
    "*Scalable K-Means++*\n",
    "\n",
    "**Abstract**\n",
    "\n",
    "*K-means* is one of the most popular clustering methods. A good initialization of *k-means* is essential for obtaining the global optimal solution and efficiency. However, there are two main obstacles with traditional *k-means* method. One is theoretical inefficiency and the other one is that its final solution is locally optimal. A better algorithm, *k-means++* addresses the second problem with an improved initialization procedure of the cluster centers. But this *k-means++* initialization is not parallelizable, because the selection for the *i*th center depends on the previous *i-1* centers [1]. Therefore, *k-means||*, a parallelizable version of *k-means++*, has been raised, which can both improve the final solution and run faster. In this report, we implemented the algorithm in the paper \"Scalable K-Means++\" in Python, compared the clustering cost and runtime between *k-means*, *k-means++* and *k-means||*, performed tests for main functions, profiled the performance of the algorithm and identified bottlenecks, and performed optimization using Cython. We then apply *k-means||* to a massive dataset to evaluate its performance.\n",
    "\n",
    "**Outline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "2. Algorithm  \n",
    "    2.1 K-Means  \n",
    "    2.2 K-Means++  \n",
    "    2.3 K-Means||  \n",
    "3. Code Testing\n",
    "4. Profiling and Optimization\n",
    "5. Application and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.linalg as la\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def euc_dist(x, y):\n",
    "    return la.norm(x-y)\n",
    "\n",
    "def centroid(X):\n",
    "    return X.mean(0)\n",
    "    \n",
    "def d(x, Y):\n",
    "    minDist = float(\"inf\")\n",
    "    for yi in Y:\n",
    "        dist = euc_dist(x, yi)\n",
    "        if(dist < minDist):\n",
    "            minDist = dist\n",
    "    return minDist\n",
    "\n",
    "def cost(Y, C):\n",
    "    cost = 0\n",
    "    for yi in Y:\n",
    "        cost += d(yi, C)**2\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# K-Means++\n",
    "def kmeansPlus(data, k):\n",
    "    idx = np.random.choice(data.shape[0], 1)\n",
    "    C = data[idx, :]\n",
    "    while(C.shape[0] < k):\n",
    "        prob = [d(xi,C)**2 for xi in data]/cost(data,C)\n",
    "        new = data[np.random.choice(data.shape[0], size=1, p=prob),:]\n",
    "        if(new.tolist() not in C.tolist()):\n",
    "            C = np.r_[C, new]\n",
    "    return C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialization algorithm: k-means||**  \n",
    "*k-means||* uses an oversampling factor *l* = $\\Omega$(k), which is unlike *k-means++*. Intuitively, *l* should be thought of as $\\Theta$(k). This initialization algorithm picks an initial center uniformly from the dataset and computes $\\psi$, here is initial cost of the clustering of this selection. Then do log$\\psi$ iterations and in each iteration, it samples each x with probability *l*$d^2(x,C)/\\psi_X(C)$ given current set C of centers. If the point is sampled, it will be added to C and the quantity $\\phi_X(C)$ updated and interation continued."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Algorithm*** *k-means||*(k,l)initialization  \n",
    "1. C <- sample a point uniformly at random from X  \n",
    "2. $\\psi$ = $\\phi_X(C)$  \n",
    "3. for O(log$\\psi$) times do  \n",
    "      C' <- sample each point x $\\in$ X independently with probability $p_x = \\frac{l*d^2(x,C)}{\\phi_X(C)}$  \n",
    "      C <- C $\\cup$ C'  \n",
    "   end for  \n",
    "4. For x $\\in$ C, set $w_x$ to be the number of points in X closer to x than any other point in C  \n",
    "5. Recluster the weighted points in C into k clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "first centroid: [[ 3.  5.]]\n",
      "initial cost: 390.36999999999995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1. ,   0. ],\n",
       "       [  1.5,   0. ],\n",
       "       [  3. ,   4.8],\n",
       "       [  3.6,   4.5],\n",
       "       [  4. ,   4.9],\n",
       "       [  9. ,  12. ],\n",
       "       [  9. ,  11.5],\n",
       "       [  8.7,  11.7],\n",
       "       [  8.5,  11.2],\n",
       "       [  1.3,   0.5]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K-Means||\n",
    "X_ori = np.array([[1,0],[1.5,0],[3,5],[3,4.8],[3.6,4.5],[4,4.9],[9,12],[9,11.5],[8.7,11.7],[8.5,11.2],[1.3,0.5]])\n",
    "X = X_ori\n",
    "k = 3\n",
    "l = 2\n",
    "##step1\n",
    "##Sample a point uniformly at random from X\n",
    "idx1 = np.random.choice(X_ori.shape[0],1,replace = False)\n",
    "C = X[idx1-1,:]\n",
    "print(idx1)\n",
    "print(\"first centroid:\",C)\n",
    "##step2\n",
    "##initial cost\n",
    "gamma1 = cost(X,C)\n",
    "print(\"initial cost:\",gamma1)\n",
    "##remove first centroid\n",
    "X = np.delete(X, idx1-1, axis=0)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9. ,  12. ],\n",
       "       [  1.5,   0. ],\n",
       "       [  4. ,   4.9],\n",
       "       [  3. ,   5. ]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##step3-6\n",
    "for i in range(int(round(np.log(gamma1))/k)):\n",
    "    Ct = []\n",
    "    idx = []\n",
    "    gamma = cost(X,C)\n",
    "    prob = [l*d(x,C)**2/gamma for x in X]\n",
    "    #new = data[np.random.choice(X.shape[0], size=1, p=prob),:]\n",
    "    for j in range(len(X)):\n",
    "        point = np.random.binomial(1,prob[j],size = 1)\n",
    "        if point == 1:\n",
    "           Ct.append(X[j,:])\n",
    "           idx.append(j)\n",
    "    X = np.delete(X, idx, axis = 0)\n",
    "    C = np.concatenate((C,np.array(Ct).reshape(len(Ct),2)),axis = 0)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 1, 2]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##step7\n",
    "w = []\n",
    "for c in C:\n",
    "    distxc = [euc_dist(x,c) for x in X]\n",
    "    distc = [euc_dist(y,c) for y in C]\n",
    "    distc.remove(0)\n",
    "    count = 0\n",
    "    for p in distxc:\n",
    "        if p < min(distc):\n",
    "           count += 1\n",
    "    w.append(count)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 0])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##step8\n",
    "w_prob = w/np.sum(w)\n",
    "w_prob\n",
    "centroid = np.random.choice(range(C.shape[0]),k,p = w_prob,replace = False)\n",
    "centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight(X,C):\n",
    "    w = []\n",
    "    for c in C:\n",
    "        distxc = [euc_dist(x,c) for x in X]\n",
    "        distc = [euc_dist(y,c) for y in C]\n",
    "        distc.remove(0)\n",
    "        count = 0\n",
    "        for p in distxc:\n",
    "           if p < min(distc):\n",
    "               count += 1\n",
    "        w.append(count)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##k-means||\n",
    "def kmeansparallel(X_ori,k,l):\n",
    "    X = X_ori\n",
    "    ##Sample a point uniformly at random from X\n",
    "    idx1 = np.random.choice(X_ori.shape[0],1,replace = False)\n",
    "    C = X[idx1-1,:]\n",
    "    print(idx1)\n",
    "    print(\"first centroid:\",C)\n",
    "    ##initial cost\n",
    "    gamma1 = cost(X,C)\n",
    "    print(\"initial cost:\",gamma1)\n",
    "    ##remove first centroid\n",
    "    X = np.delete(X, idx1-1, axis=0)\n",
    "    for i in range(int(round(np.log(gamma1))/k)):\n",
    "        Ct = []\n",
    "        idx = []\n",
    "        gamma = cost(X,C)\n",
    "        prob = [l*d(x,C)**2/gamma for x in X]\n",
    "        #new = data[np.random.choice(X.shape[0], size=1, p=prob),:]\n",
    "        for j in range(len(X)):\n",
    "            point = np.random.binomial(1,prob[j],size = 1)\n",
    "            if point == 1:\n",
    "               Ct.append(X[j,:])\n",
    "               idx.append(j)\n",
    "        X = np.delete(X, idx, axis = 0)\n",
    "        C = np.concatenate((C,np.array(Ct).reshape(len(Ct),2)),axis = 0)\n",
    "    ##step7\n",
    "    w = []\n",
    "    for c in C:\n",
    "        distxc = [euc_dist(x,c) for x in X]\n",
    "        distc = [euc_dist(y,c) for y in C]\n",
    "        distc.remove(0)\n",
    "        count = 0\n",
    "        for p in distxc:\n",
    "           if p < min(distc):\n",
    "               count += 1\n",
    "        w.append(count)\n",
    "    ##step8\n",
    "    w_prob = w/np.sum(w)\n",
    "    centroid = np.random.choice(range(C.shape[0]),k,p = w_prob,replace = False)\n",
    "    return C[centroid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "first centroid: [[ 3.  5.]]\n",
      "initial cost: 390.36999999999995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  3. ,   5. ],\n",
       "       [  9. ,  12. ],\n",
       "       [  8.5,  11.2]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeansparallel(X_ori,k,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
